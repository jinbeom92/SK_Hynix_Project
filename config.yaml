# ==============================================================================
# HDN (Enc1+Enc2 → Align → Fusion → SinoDecoder → Unfiltered BP) — Training Config
#
# Overview
# --------
# • Data: Paired sinogram/voxel files. The dataset expects sinograms in [U(=X), A, D]
#   and voxels in [X, Y, D]. Each training sample is a single z-slice.
# • Geometry: Parallel-beam 3D geometry defined in model-facing coords (X,Y,Z) and
#   detector (X,Z). Angles are inferred per group from data (0..π, A samples).
# • Model: Sinogram encoders (1D over A, 2D over X×A), alignment to XY, optional
#   cheat features from GT voxels (training only), fusion on XY, then a decoder
#   mapping XY→XA to produce an optimized sinogram; backprojection is unfiltered.
# • Loss: ExpandMaskedMSE only. It trains on in-part + near-boundary out-of-part
#   pixels, with soft boundary targets and all far out-of-part masked out.
# • Train loop: Slice-wise training with AMP, gradient clipping, CSV logging, and
#   group-wise evaluation by stacking slice reconstructions into volumes.
#
# Notes
# -----
# • All tensors obey the fixed axis convention:
#       Sinogram (x,a,z) → [B, 1, X, A, Z]
#       Volume   (x,y,z) → [B, 1, X, Y, Z]
# • Backprojection uses a differentiable, unfiltered angular accumulation
#   (no frequency-domain filter), with optional circular support masking.
# ==============================================================================

data:
  root: dataset
  sino_glob: "sino/*_sino.npy"
  voxel_glob: "voxel/*_voxel.npy"

projector:
  method: "joseph3d"

geom:
  voxel_size_xyz: [1.0, 1.0, 1.0]
  det_spacing_xz: [1.0, 1.0]
  angle_chunk: 16
  n_steps_cap: 256

model:
  enc1:   { base: 32, depth: 3 }
  enc2:   { base: 32, depth: 3 }
  align:  { out_ch: 64, depth: 2, interp_mode: "bilinear" }
  cheat2d: { enabled: true, base: 16, depth: 2 }
  fusion: { out_ch: 64 }
  sino_dec: { mid_ch: 64, depth: 2, interp_mode: "bilinear" }

losses:
  expand_thr: 0.8
  expand_spacing: null
  expand_include_in: true
  expand_in_value: 1.0
  expand_boundary_low: 0.8
  expand_boundary_high: 0.9
  expand_clamp: true

train:
  seed: 1337
  amp: true
  amp_dtype: "auto"
  optimizer: "adamw"
  lr: 1.0e-4
  weight_decay: 1.0e-3
  batch_size: 8
  num_workers: 2
  grad_clip: 1.0
  grad_accum_steps: 1
  train_ratio: 0.8
  files_per_group: 100
  epochs: 1
  epochs_per_group: 1
  ckpt_dir: "checkpoints/hdn_josephfbp_mse"
  compile: false
  flush_every: 10
  empty_cache_every: 100
